{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXDyDRU2ND2w",
    "outputId": "55f86125-7d48-4797-b22b-9809f8f97326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘tiny-imagenet-200.zip’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import models\n",
    "import loader\n",
    "import time\n",
    "import torchsummary\n",
    "from importlib import reload\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# @TODO: dataset.download()\n",
    "!wget -nc http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "    \n",
    "# run this script only once\n",
    "!unzip tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9qVGCB3BN29h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded in 12.486455202102661 s\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "dataset = loader.TinyImageNet200()\n",
    "dataset.prepare(split=loader.TRAIN)\n",
    "print('train dataset has loaded in', time.time() - before, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "U9Try2C_w_x7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded in 1.4639499187469482 s\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "valid = loader.TinyImageNet200()\n",
    "valid.prepare(split=loader.VALID)\n",
    "print('validation dataset has loaded in', time.time() - before, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AUJv0Xs1S45l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3, 64, 64]) torch.Size([12])\n",
      "torch.Size([12, 200])\n",
      "torch.Size([12]) torch.Size([12, 200]) 5.699825286865234\n",
      "tensor([ 99,  29, 113, 185, 100, 187, 115, 166,  88,  50,  67,  64])\n",
      "tensor([ 92,  71,  24, 155, 172,  92,  71, 172, 172,  71, 172, 172])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# an example batch is processed here\n",
    "x, y = next(iter(dataset.dataloader(batch_size=12)))\n",
    "print('input shape', x.shape, 'target shape', y.shape)\n",
    "pred = model.cpu()(x)\n",
    "print('preds shape', pred.shape)\n",
    "loss = torch.nn.functional.nll_loss(pred.log(), y)\n",
    "print('example targets', y.detach().numpy().tolist())\n",
    "print('example preds', pred.argmax(1).detach().numpy().tolist())\n",
    "print('loss score', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "aP12_pEitq5T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import accuracy, f1_score\n",
    "import models\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "reload(models)\n",
    "\n",
    "\n",
    "def train(model_params, train_data, valid_data, num_epochs, num_epochs_per_validation, verbose=True, **config):\n",
    "    # create a model with given parameters\n",
    "    model = models.ResidualNet(**model_params)\n",
    "    torchsummary.summary(model, input_size=(3, 64, 64), device='cpu', batch_size=config['batch_size'])\n",
    "    \n",
    "    # initialize loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                                 weight_decay=config.setdefault('weight_decay', 0))\n",
    "    \n",
    "    # if plateau_monitor is set to a value then monitor it in scheduler\n",
    "    if 'plateau_monitor' in config and config['plateau_monitor'] is not None:\n",
    "        monitor = config['plateau_monitor']\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    \n",
    "    # initialize a wandb session\n",
    "    wandb.init(project='imagenet', entity='adnanhd', \n",
    "               name='avg-pool', config={**config, **model_params})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    # initialize dataloaders from Datasets defined in loader.py\n",
    "    train_dataloader = train_data.dataloader(batch_size=config['batch_size'])\n",
    "    valid_dataloader = valid_data.dataloader()\n",
    "    num_of_train_batchs = len(train_dataloader)\n",
    "\n",
    "    # return value for further comparison\n",
    "    valid_accuracy = []\n",
    "    pbar = tqdm(range(1, num_epochs + 1))\n",
    "    for n in pbar:\n",
    "        pbar.set_description(f'Epoch {n} of {num_epochs}')\n",
    "        log = {'loss': 0, 'accuracy': 0, 'f1_score': 0}\n",
    "        for x, y in train_dataloader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            pred = model.cuda()(x)\n",
    "            loss = criterion(pred.log(), y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            log['loss'] += loss.item()\n",
    "            log['accuracy'] += accuracy(preds=pred, target=y, num_classes=200, average='macro').item()\n",
    "            log['f1_score'] += f1_score(preds=pred, target=y).item()\n",
    "            del x, y, pred\n",
    "        log['loss'] /= num_of_train_batchs\n",
    "        log['accuracy'] /= num_of_train_batchs\n",
    "        log['f1_score'] /= num_of_train_batchs\n",
    "        pbar.set_postfix(log)\n",
    "        wandb.log(log, step=n)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(log[monitor])\n",
    "        if n % num_epochs_per_validation == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_log = {}\n",
    "                for x, y in valid_dataloader:\n",
    "                    pred = model.cpu()(x)\n",
    "                    loss = criterion(pred.log(), y)\n",
    "                    valid_log['val_loss'] = loss.item()\n",
    "                    valid_log['val_accuracy'] = accuracy(preds=pred, target=y).item()\n",
    "                    valid_log['val_f1_score'] = f1_score(preds=pred, target=y).item()\n",
    "                    valid_accuracy.append(valid_log['val_accuracy'])\n",
    "                    wandb.log(valid_log, step=n)\n",
    "    return sum(valid_accuracy) / len(valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "sjEhFMQpXktf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [1000, 32, 32, 32]             896\n",
      "              ReLU-2         [1000, 32, 32, 32]               0\n",
      "         AvgPool2d-3         [1000, 32, 10, 10]               0\n",
      "            Conv2d-4        [1000, 128, 10, 10]          36,992\n",
      "              ReLU-5        [1000, 128, 10, 10]               0\n",
      "            Conv2d-6         [1000, 32, 10, 10]          36,896\n",
      "              ReLU-7         [1000, 32, 10, 10]               0\n",
      "            Conv2d-8         [1000, 64, 10, 10]          18,496\n",
      "     ResidualBlock-9         [1000, 64, 10, 10]               0\n",
      "           Conv2d-10        [1000, 256, 10, 10]         147,712\n",
      "             ReLU-11        [1000, 256, 10, 10]               0\n",
      "           Conv2d-12         [1000, 64, 10, 10]         147,520\n",
      "             ReLU-13         [1000, 64, 10, 10]               0\n",
      "           Conv2d-14        [1000, 128, 10, 10]          73,856\n",
      "    ResidualBlock-15        [1000, 128, 10, 10]               0\n",
      "           Conv2d-16          [1000, 128, 5, 5]         147,584\n",
      "             ReLU-17          [1000, 128, 5, 5]               0\n",
      "        ConvBlock-18          [1000, 128, 5, 5]               0\n",
      "        AvgPool2d-19          [1000, 128, 1, 1]               0\n",
      "          Reshape-20                [1000, 128]               0\n",
      "           Linear-21                [1000, 200]          25,800\n",
      "================================================================\n",
      "Total params: 635,752\n",
      "Trainable params: 635,752\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 46.88\n",
      "Forward/backward pass size (MB): 1626.53\n",
      "Params size (MB): 2.43\n",
      "Estimated Total Size (MB): 1675.83\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:136u38sb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.005</td></tr><tr><td>f1_score</td><td>0.005</td></tr><tr><td>loss</td><td>5.29869</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">avg-pool</strong>: <a href=\"https://wandb.ai/adnanhd/imagenet/runs/136u38sb\" target=\"_blank\">https://wandb.ai/adnanhd/imagenet/runs/136u38sb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220803_170237-136u38sb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:136u38sb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ceng/public/databoss/wandb/run-20220803_170715-ekrulrld</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/adnanhd/imagenet/runs/ekrulrld\" target=\"_blank\">avg-pool</a></strong> to <a href=\"https://wandb.ai/adnanhd/imagenet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 100:   1%|▌                                                            | 1/100 [00:21<35:32, 21.54s/it, loss=5.3, accuracy=0.00504, f1_score=0.005]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresidual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m           \u001b[49m\u001b[43mconv_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_params, train_data, valid_data, num_epochs, num_epochs_per_validation, **config)\u001b[0m\n\u001b[1;32m     33\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/envs/ood/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/envs/ood/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/envs/ood/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/envs/ood/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/public/databoss/loader.py:67\u001b[0m, in \u001b[0;36mTinyImageNet200.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     65\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[1;32m     66\u001b[0m float64 \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 67\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfloat64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(item) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, item[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# an example individual/singleton run\n",
    "train(dict(residual=True, pool='avg', batch_norm=False, pool_stride=3,\n",
    "           conv_kernel_size=3, pool_kernel_size=3, linear_output=128), \n",
    "      dataset, valid, 100, 10, batch_size=1000, learning_rate=4e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe\n",
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for hardcoding the num of params before the last fc layer (a.k.a. linear_output)\n",
    "linear_output_dict = {}\n",
    "def get_linear_output_dict(conv_kernel_size=3, pool_kernel_size=3, pool_stride=3, **kwargs):\n",
    "    return linear_output_dict[(conv_kernel_size, pool_kernel_size, pool_stride)]\n",
    "\n",
    "def set_linear_output_dict(linear_output, conv_kernel_size=3, pool_kernel_size=3, pool_stride=3):\n",
    "    linear_output_dict[(conv_kernel_size, pool_kernel_size, pool_stride)] = linear_output\n",
    "\n",
    "\n",
    "set_linear_output_dict(conv_kernel_size=2, pool_kernel_size=2, pool_stride=2, linear_output=2048)\n",
    "set_linear_output_dict(conv_kernel_size=2, pool_kernel_size=2, pool_stride=3, linear_output=512)\n",
    "set_linear_output_dict(conv_kernel_size=2, pool_kernel_size=3, pool_stride=2, linear_output=1152)\n",
    "set_linear_output_dict(conv_kernel_size=2, pool_kernel_size=3, pool_stride=3, linear_output=512)\n",
    "\n",
    "set_linear_output_dict(conv_kernel_size=3, pool_kernel_size=2, pool_stride=2, linear_output=2048)\n",
    "set_linear_output_dict(conv_kernel_size=3, pool_kernel_size=2, pool_stride=3, linear_output=512)\n",
    "set_linear_output_dict(conv_kernel_size=3, pool_kernel_size=3, pool_stride=2, linear_output=1152)\n",
    "set_linear_output_dict(conv_kernel_size=3, pool_kernel_size=3, pool_stride=3, linear_output=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this space defines ranges and possibilities that our hyperparameters can take\n",
    "EXPERIMENT_SPACE = OrderedDict([\n",
    "    ('learning_rate', hp.loguniform('learning_rate', math.log(1e-7), math.log(1e-5))), # learning rate\n",
    "    ('residual', hp.choice('residual', (True, False))), # residual network\n",
    "    ('batch_norm', hp.choice('batch_norm', (True, False))), # batch normalization\n",
    "    ('weight_decay', hp.choice('weight_decay', [0, 1e-2, 1e-4, 4e-5])), # regularization\n",
    "    ('pool', hp.choice('pool', ('avg', 'max'))), # pooling\n",
    "    ('conv_kernel_size', hp.choice('conv_kernel_size', range(2, 4, 1))), # kernel size\n",
    "    ('pool_kernel_size', hp.choice('pool_kernel_size', range(2, 4, 1))),\n",
    "    ('pool_stride', hp.choice('pool_stride', range(2, 4, 1))), # stride\n",
    "    ('plateau_monitor', hp.choice('plateau_monitor', [None, 'f1_score', 'accuracy', 'loss'])), # lr plateau\n",
    "    ('batch_size', hp.choice('batch_size', [1000, 2000, 5000, 10000])), # batch_size\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this objective function is applied in bayesian process to find the current accuracy\n",
    "def objective(params):\n",
    "    config = {key: params[key] for key in ('learning_rate', 'weight_decay', 'plateau_monitor', 'batch_size')}\n",
    "    model_params = {key: params[key] for key in ('residual', 'batch_norm', 'pool', 'pool_stride',\n",
    "                                                 'conv_kernel_size', 'pool_kernel_size')}\n",
    "    print('model_params', model_params)\n",
    "    linear_output_kwargs = {key: params[key] for key in ('conv_kernel_size', 'pool_kernel_size', 'pool_stride')}\n",
    "    model_params['linear_output'] = get_linear_output_dict(**linear_output_kwargs)\n",
    "    accuracy = train(model_params, dataset, valid, num_epochs=200, **config, num_epochs_per_validation=10)\n",
    "    # here hyperopt library tries to minimize 'loss' value therefore \n",
    "    # taking the negative logarithm of accuracy get it done.\n",
    "    print('accuracy is', accuracy)\n",
    "    return {'loss': abs(-math.log(accuracy)), 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_params                                                                                                                                                  \n",
      "{'residual': True, 'batch_norm': True, 'pool': 'avg', 'pool_stride': 3, 'conv_kernel_size': 2, 'pool_kernel_size': 3}                                         \n",
      "----------------------------------------------------------------                                                                                              \n",
      "        Layer (type)               Output Shape         Param #                                                                                               \n",
      "================================================================                                                                                              \n",
      "            Conv2d-1         [5000, 32, 32, 32]             896                                                                                               \n",
      "       BatchNorm2d-2         [5000, 32, 32, 32]              64                                                                                               \n",
      "              ReLU-3         [5000, 32, 32, 32]               0                                                                                               \n",
      "         AvgPool2d-4         [5000, 32, 10, 10]               0                                                                                               \n",
      "            Conv2d-5        [5000, 128, 10, 10]          36,992                                                                                               \n",
      "       BatchNorm2d-6        [5000, 128, 10, 10]             256                                                                                               \n",
      "              ReLU-7        [5000, 128, 10, 10]               0                                                                                               \n",
      "            Conv2d-8         [5000, 32, 10, 10]          36,896                                                                                               \n",
      "       BatchNorm2d-9         [5000, 32, 10, 10]              64                                                                                               \n",
      "             ReLU-10         [5000, 32, 10, 10]               0                                                                                               \n",
      "           Conv2d-11         [5000, 64, 10, 10]          18,496                                                                                               \n",
      "      BatchNorm2d-12         [5000, 64, 10, 10]             128                                                                                               \n",
      "    ResidualBlock-13         [5000, 64, 10, 10]               0                                                                                               \n",
      "           Conv2d-14        [5000, 256, 10, 10]         147,712                                                                                               \n",
      "      BatchNorm2d-15        [5000, 256, 10, 10]             512                                                                                               \n",
      "             ReLU-16        [5000, 256, 10, 10]               0                                                                                               \n",
      "           Conv2d-17         [5000, 64, 10, 10]         147,520                                                                                               \n",
      "      BatchNorm2d-18         [5000, 64, 10, 10]             128                                                                                               \n",
      "             ReLU-19         [5000, 64, 10, 10]               0                                                                                               \n",
      "           Conv2d-20        [5000, 128, 10, 10]          73,856                                                                                               \n",
      "      BatchNorm2d-21        [5000, 128, 10, 10]             256                                                                                               \n",
      "    ResidualBlock-22        [5000, 128, 10, 10]               0                                                                                               \n",
      "           Conv2d-23          [5000, 128, 6, 6]          65,664                                                                                               \n",
      "      BatchNorm2d-24          [5000, 128, 6, 6]             256                                                                                               \n",
      "             ReLU-25          [5000, 128, 6, 6]               0                                                                                               \n",
      "        ConvBlock-26          [5000, 128, 6, 6]               0                                                                                               \n",
      "        AvgPool2d-27          [5000, 128, 2, 2]               0                                                                                               \n",
      "          Reshape-28                [5000, 512]               0                                                                                               \n",
      "           Linear-29                [5000, 200]         102,600                                                                                               \n",
      "================================================================                                                                                              \n",
      "Total params: 632,296                                                                                                                                         \n",
      "Trainable params: 632,296                                                                                                                                     \n",
      "Non-trainable params: 0                                                                                                                                       \n",
      "----------------------------------------------------------------                                                                                              \n",
      "Input size (MB): 234.38                                                                                                                                       \n",
      "Forward/backward pass size (MB): 12312.32                                                                                                                     \n",
      "Params size (MB): 2.41                                                                                                                                        \n",
      "Estimated Total Size (MB): 12549.10                                                                                                                           \n",
      "----------------------------------------------------------------                                                                                              \n",
      "  0%|                                                                                                 | 0/9223372036854775807 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ekrulrld) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.00504</td></tr><tr><td>f1_score</td><td>0.005</td></tr><tr><td>loss</td><td>5.29973</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">avg-pool</strong>: <a href=\"https://wandb.ai/adnanhd/imagenet/runs/ekrulrld\" target=\"_blank\">https://wandb.ai/adnanhd/imagenet/runs/ekrulrld</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220803_170715-ekrulrld/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ekrulrld). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ceng/public/databoss/wandb/run-20220803_170756-3m8chm34</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/adnanhd/imagenet/runs/3m8chm34\" target=\"_blank\">avg-pool</a></strong> to <a href=\"https://wandb.ai/adnanhd/imagenet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1 of 200:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1 of 200:   0%|          | 0/200 [00:14<?, ?it/s, loss=5.33, accuracy=0.00471, f1_score=0.00469]\u001b[A\n",
      "Epoch 1 of 200:   0%|          | 1/200 [00:14<48:05, 14.50s/it, loss=5.33, accuracy=0.00471, f1_score=0.00469]\u001b[A\n",
      "Epoch 2 of 200:   0%|          | 1/200 [00:14<48:05, 14.50s/it, loss=5.33, accuracy=0.00471, f1_score=0.00469]\u001b[A\n",
      "Epoch 2 of 200:   0%|          | 1/200 [00:29<48:05, 14.50s/it, loss=5.33, accuracy=0.0049, f1_score=0.00483] \u001b[A\n",
      "Epoch 2 of 200:   1%|1         | 2/200 [00:29<47:51, 14.50s/it, loss=5.33, accuracy=0.0049, f1_score=0.00483]\u001b[A\n",
      "Epoch 3 of 200:   1%|1         | 2/200 [00:29<47:51, 14.50s/it, loss=5.33, accuracy=0.0049, f1_score=0.00483]\u001b[A\n",
      "Epoch 3 of 200:   1%|1         | 2/200 [00:43<47:51, 14.50s/it, loss=5.33, accuracy=0.00473, f1_score=0.00473]\u001b[A\n",
      "Epoch 3 of 200:   2%|1         | 3/200 [00:43<47:38, 14.51s/it, loss=5.33, accuracy=0.00473, f1_score=0.00473]\u001b[A\n",
      "Epoch 4 of 200:   2%|1         | 3/200 [00:43<47:38, 14.51s/it, loss=5.33, accuracy=0.00473, f1_score=0.00473]\u001b[A\n",
      "Epoch 4 of 200:   2%|1         | 3/200 [00:57<47:38, 14.51s/it, loss=5.33, accuracy=0.00484, f1_score=0.00484]\u001b[A\n",
      "Epoch 4 of 200:   2%|2         | 4/200 [00:57<47:13, 14.46s/it, loss=5.33, accuracy=0.00484, f1_score=0.00484]\u001b[A\n",
      "Epoch 5 of 200:   2%|2         | 4/200 [00:57<47:13, 14.46s/it, loss=5.33, accuracy=0.00484, f1_score=0.00484]\u001b[A\n",
      "Epoch 5 of 200:   2%|2         | 4/200 [01:12<47:13, 14.46s/it, loss=5.33, accuracy=0.00483, f1_score=0.00486]\u001b[A\n",
      "Epoch 5 of 200:   2%|2         | 5/200 [01:12<47:03, 14.48s/it, loss=5.33, accuracy=0.00483, f1_score=0.00486]\u001b[A\n",
      "Epoch 6 of 200:   2%|2         | 5/200 [01:12<47:03, 14.48s/it, loss=5.33, accuracy=0.00483, f1_score=0.00486]\u001b[A\n",
      "Epoch 6 of 200:   2%|2         | 5/200 [01:26<47:03, 14.48s/it, loss=5.33, accuracy=0.00488, f1_score=0.00488]\u001b[A\n",
      "Epoch 6 of 200:   3%|3         | 6/200 [01:26<46:45, 14.46s/it, loss=5.33, accuracy=0.00488, f1_score=0.00488]\u001b[A\n",
      "Epoch 7 of 200:   3%|3         | 6/200 [01:26<46:45, 14.46s/it, loss=5.33, accuracy=0.00488, f1_score=0.00488]\u001b[A\n",
      "Epoch 7 of 200:   3%|3         | 6/200 [01:41<46:45, 14.46s/it, loss=5.33, accuracy=0.00494, f1_score=0.00495]\u001b[A\n",
      "Epoch 7 of 200:   4%|3         | 7/200 [01:41<46:31, 14.47s/it, loss=5.33, accuracy=0.00494, f1_score=0.00495]\u001b[A\n",
      "Epoch 8 of 200:   4%|3         | 7/200 [01:41<46:31, 14.47s/it, loss=5.33, accuracy=0.00494, f1_score=0.00495]\u001b[A\n",
      "Epoch 8 of 200:   4%|3         | 7/200 [01:55<46:31, 14.47s/it, loss=5.33, accuracy=0.00495, f1_score=0.00493]\u001b[A\n",
      "Epoch 8 of 200:   4%|4         | 8/200 [01:55<46:17, 14.47s/it, loss=5.33, accuracy=0.00495, f1_score=0.00493]\u001b[A\n",
      "Epoch 9 of 200:   4%|4         | 8/200 [01:55<46:17, 14.47s/it, loss=5.33, accuracy=0.00495, f1_score=0.00493]\u001b[A\n",
      "Epoch 9 of 200:   4%|4         | 8/200 [02:10<46:17, 14.47s/it, loss=5.33, accuracy=0.00508, f1_score=0.00506]\u001b[A\n",
      "Epoch 9 of 200:   4%|4         | 9/200 [02:10<46:10, 14.51s/it, loss=5.33, accuracy=0.00508, f1_score=0.00506]\u001b[A\n",
      "Epoch 10 of 200:   4%|4         | 9/200 [02:10<46:10, 14.51s/it, loss=5.33, accuracy=0.00508, f1_score=0.00506]\u001b[A\n",
      "Epoch 10 of 200:   4%|4         | 9/200 [02:24<46:10, 14.51s/it, loss=5.33, accuracy=0.00514, f1_score=0.00517]\u001b[A\n",
      "Epoch 10 of 200:   5%|5         | 10/200 [02:29<50:35, 15.98s/it, loss=5.33, accuracy=0.00514, f1_score=0.00517]\u001b[A\n",
      "Epoch 11 of 200:   5%|5         | 10/200 [02:29<50:35, 15.98s/it, loss=5.33, accuracy=0.00514, f1_score=0.00517]\u001b[A\n",
      "Epoch 11 of 200:   5%|5         | 10/200 [02:44<50:35, 15.98s/it, loss=5.33, accuracy=0.00524, f1_score=0.00528]\u001b[A\n",
      "Epoch 11 of 200:   6%|5         | 11/200 [02:44<48:54, 15.53s/it, loss=5.33, accuracy=0.00524, f1_score=0.00528]\u001b[A\n",
      "Epoch 12 of 200:   6%|5         | 11/200 [02:44<48:54, 15.53s/it, loss=5.33, accuracy=0.00524, f1_score=0.00528]\u001b[A\n",
      "Epoch 12 of 200:   6%|5         | 11/200 [02:58<48:54, 15.53s/it, loss=5.33, accuracy=0.0053, f1_score=0.00527] \u001b[A\n",
      "Epoch 12 of 200:   6%|6         | 12/200 [02:58<47:34, 15.18s/it, loss=5.33, accuracy=0.0053, f1_score=0.00527]\u001b[A\n",
      "Epoch 13 of 200:   6%|6         | 12/200 [02:58<47:34, 15.18s/it, loss=5.33, accuracy=0.0053, f1_score=0.00527]\u001b[A\n",
      "Epoch 13 of 200:   6%|6         | 12/200 [03:13<47:34, 15.18s/it, loss=5.33, accuracy=0.00526, f1_score=0.00531]\u001b[A\n",
      "Epoch 13 of 200:   6%|6         | 13/200 [03:13<46:40, 14.98s/it, loss=5.33, accuracy=0.00526, f1_score=0.00531]\u001b[A\n",
      "Epoch 14 of 200:   6%|6         | 13/200 [03:13<46:40, 14.98s/it, loss=5.33, accuracy=0.00526, f1_score=0.00531]\u001b[A\n",
      "Epoch 14 of 200:   6%|6         | 13/200 [03:27<46:40, 14.98s/it, loss=5.33, accuracy=0.00531, f1_score=0.00529]\u001b[A\n",
      "Epoch 14 of 200:   7%|7         | 14/200 [03:27<45:54, 14.81s/it, loss=5.33, accuracy=0.00531, f1_score=0.00529]\u001b[A\n",
      "Epoch 15 of 200:   7%|7         | 14/200 [03:27<45:54, 14.81s/it, loss=5.33, accuracy=0.00531, f1_score=0.00529]\u001b[A\n",
      "Epoch 15 of 200:   7%|7         | 14/200 [03:41<45:54, 14.81s/it, loss=5.33, accuracy=0.00535, f1_score=0.00535]\u001b[A\n",
      "Epoch 15 of 200:   8%|7         | 15/200 [03:41<45:20, 14.71s/it, loss=5.33, accuracy=0.00535, f1_score=0.00535]\u001b[A\n",
      "Epoch 16 of 200:   8%|7         | 15/200 [03:41<45:20, 14.71s/it, loss=5.33, accuracy=0.00535, f1_score=0.00535]\u001b[A\n",
      "Epoch 16 of 200:   8%|7         | 15/200 [03:56<45:20, 14.71s/it, loss=5.33, accuracy=0.00532, f1_score=0.00536]\u001b[A\n",
      "Epoch 16 of 200:   8%|8         | 16/200 [03:56<44:53, 14.64s/it, loss=5.33, accuracy=0.00532, f1_score=0.00536]\u001b[A\n",
      "Epoch 17 of 200:   8%|8         | 16/200 [03:56<44:53, 14.64s/it, loss=5.33, accuracy=0.00532, f1_score=0.00536]\u001b[A\n",
      "Epoch 17 of 200:   8%|8         | 16/200 [04:10<44:53, 14.64s/it, loss=5.33, accuracy=0.00526, f1_score=0.00532]\u001b[A\n",
      "Epoch 17 of 200:   8%|8         | 17/200 [04:10<44:25, 14.57s/it, loss=5.33, accuracy=0.00526, f1_score=0.00532]\u001b[A\n",
      "Epoch 18 of 200:   8%|8         | 17/200 [04:10<44:25, 14.57s/it, loss=5.33, accuracy=0.00526, f1_score=0.00532]\u001b[A\n",
      "Epoch 18 of 200:   8%|8         | 17/200 [04:25<44:25, 14.57s/it, loss=5.33, accuracy=0.00532, f1_score=0.00529]\u001b[A\n",
      "Epoch 18 of 200:   9%|9         | 18/200 [04:25<44:01, 14.52s/it, loss=5.33, accuracy=0.00532, f1_score=0.00529]\u001b[A\n",
      "Epoch 19 of 200:   9%|9         | 18/200 [04:25<44:01, 14.52s/it, loss=5.33, accuracy=0.00532, f1_score=0.00529]\u001b[A\n",
      "Epoch 19 of 200:   9%|9         | 18/200 [04:39<44:01, 14.52s/it, loss=5.33, accuracy=0.00532, f1_score=0.00531]\u001b[A\n",
      "Epoch 19 of 200:  10%|9         | 19/200 [04:39<43:47, 14.51s/it, loss=5.33, accuracy=0.00532, f1_score=0.00531]\u001b[A\n",
      "Epoch 20 of 200:  10%|9         | 19/200 [04:39<43:47, 14.51s/it, loss=5.33, accuracy=0.00532, f1_score=0.00531]\u001b[A\n",
      "Epoch 20 of 200:  10%|9         | 19/200 [04:54<43:47, 14.51s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053] \u001b[A\n",
      "Epoch 20 of 200:  10%|#         | 20/200 [04:59<47:49, 15.94s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 21 of 200:  10%|#         | 20/200 [04:59<47:49, 15.94s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 21 of 200:  10%|#         | 20/200 [05:13<47:49, 15.94s/it, loss=5.33, accuracy=0.00536, f1_score=0.00533]\u001b[A\n",
      "Epoch 21 of 200:  10%|#         | 21/200 [05:13<46:17, 15.52s/it, loss=5.33, accuracy=0.00536, f1_score=0.00533]\u001b[A\n",
      "Epoch 22 of 200:  10%|#         | 21/200 [05:13<46:17, 15.52s/it, loss=5.33, accuracy=0.00536, f1_score=0.00533]\u001b[A\n",
      "Epoch 22 of 200:  10%|#         | 21/200 [05:27<46:17, 15.52s/it, loss=5.33, accuracy=0.00532, f1_score=0.00536]\u001b[A\n",
      "Epoch 22 of 200:  11%|#1        | 22/200 [05:27<45:02, 15.18s/it, loss=5.33, accuracy=0.00532, f1_score=0.00536]\u001b[A\n",
      "Epoch 23 of 200:  11%|#1        | 22/200 [05:27<45:02, 15.18s/it, loss=5.33, accuracy=0.00532, f1_score=0.00536]\u001b[A\n",
      "Epoch 23 of 200:  11%|#1        | 22/200 [05:42<45:02, 15.18s/it, loss=5.33, accuracy=0.00533, f1_score=0.00534]\u001b[A\n",
      "Epoch 23 of 200:  12%|#1        | 23/200 [05:42<44:04, 14.94s/it, loss=5.33, accuracy=0.00533, f1_score=0.00534]\u001b[A\n",
      "Epoch 24 of 200:  12%|#1        | 23/200 [05:42<44:04, 14.94s/it, loss=5.33, accuracy=0.00533, f1_score=0.00534]\u001b[A\n",
      "Epoch 24 of 200:  12%|#1        | 23/200 [05:56<44:04, 14.94s/it, loss=5.33, accuracy=0.00538, f1_score=0.0053] \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 of 200:  12%|#2        | 24/200 [05:56<43:19, 14.77s/it, loss=5.33, accuracy=0.00538, f1_score=0.0053]\u001b[A\n",
      "Epoch 25 of 200:  12%|#2        | 24/200 [05:56<43:19, 14.77s/it, loss=5.33, accuracy=0.00538, f1_score=0.0053]\u001b[A\n",
      "Epoch 25 of 200:  12%|#2        | 24/200 [06:11<43:19, 14.77s/it, loss=5.33, accuracy=0.00527, f1_score=0.00531]\u001b[A\n",
      "Epoch 25 of 200:  12%|#2        | 25/200 [06:11<42:49, 14.68s/it, loss=5.33, accuracy=0.00527, f1_score=0.00531]\u001b[A\n",
      "Epoch 26 of 200:  12%|#2        | 25/200 [06:11<42:49, 14.68s/it, loss=5.33, accuracy=0.00527, f1_score=0.00531]\u001b[A\n",
      "Epoch 26 of 200:  12%|#2        | 25/200 [06:25<42:49, 14.68s/it, loss=5.33, accuracy=0.00529, f1_score=0.00527]\u001b[A\n",
      "Epoch 26 of 200:  13%|#3        | 26/200 [06:25<42:19, 14.59s/it, loss=5.33, accuracy=0.00529, f1_score=0.00527]\u001b[A\n",
      "Epoch 27 of 200:  13%|#3        | 26/200 [06:25<42:19, 14.59s/it, loss=5.33, accuracy=0.00529, f1_score=0.00527]\u001b[A\n",
      "Epoch 27 of 200:  13%|#3        | 26/200 [06:40<42:19, 14.59s/it, loss=5.33, accuracy=0.00528, f1_score=0.00529]\u001b[A\n",
      "Epoch 27 of 200:  14%|#3        | 27/200 [06:40<41:58, 14.56s/it, loss=5.33, accuracy=0.00528, f1_score=0.00529]\u001b[A\n",
      "Epoch 28 of 200:  14%|#3        | 27/200 [06:40<41:58, 14.56s/it, loss=5.33, accuracy=0.00528, f1_score=0.00529]\u001b[A\n",
      "Epoch 28 of 200:  14%|#3        | 27/200 [06:54<41:58, 14.56s/it, loss=5.33, accuracy=0.00535, f1_score=0.00536]\u001b[A\n",
      "Epoch 28 of 200:  14%|#4        | 28/200 [06:54<41:34, 14.50s/it, loss=5.33, accuracy=0.00535, f1_score=0.00536]\u001b[A\n",
      "Epoch 29 of 200:  14%|#4        | 28/200 [06:54<41:34, 14.50s/it, loss=5.33, accuracy=0.00535, f1_score=0.00536]\u001b[A\n",
      "Epoch 29 of 200:  14%|#4        | 28/200 [07:08<41:34, 14.50s/it, loss=5.33, accuracy=0.00541, f1_score=0.0053] \u001b[A\n",
      "Epoch 29 of 200:  14%|#4        | 29/200 [07:08<41:19, 14.50s/it, loss=5.33, accuracy=0.00541, f1_score=0.0053]\u001b[A\n",
      "Epoch 30 of 200:  14%|#4        | 29/200 [07:08<41:19, 14.50s/it, loss=5.33, accuracy=0.00541, f1_score=0.0053]\u001b[A\n",
      "Epoch 30 of 200:  14%|#4        | 29/200 [07:23<41:19, 14.50s/it, loss=5.33, accuracy=0.00534, f1_score=0.00532]\u001b[A\n",
      "Epoch 30 of 200:  15%|#5        | 30/200 [07:28<45:05, 15.92s/it, loss=5.33, accuracy=0.00534, f1_score=0.00532]\u001b[A\n",
      "Epoch 31 of 200:  15%|#5        | 30/200 [07:28<45:05, 15.92s/it, loss=5.33, accuracy=0.00534, f1_score=0.00532]\u001b[A\n",
      "Epoch 31 of 200:  15%|#5        | 30/200 [07:42<45:05, 15.92s/it, loss=5.33, accuracy=0.00523, f1_score=0.00534]\u001b[A\n",
      "Epoch 31 of 200:  16%|#5        | 31/200 [07:42<43:37, 15.49s/it, loss=5.33, accuracy=0.00523, f1_score=0.00534]\u001b[A\n",
      "Epoch 32 of 200:  16%|#5        | 31/200 [07:42<43:37, 15.49s/it, loss=5.33, accuracy=0.00523, f1_score=0.00534]\u001b[A\n",
      "Epoch 32 of 200:  16%|#5        | 31/200 [07:56<43:37, 15.49s/it, loss=5.33, accuracy=0.0054, f1_score=0.00527] \u001b[A\n",
      "Epoch 32 of 200:  16%|#6        | 32/200 [07:56<42:26, 15.16s/it, loss=5.33, accuracy=0.0054, f1_score=0.00527]\u001b[A\n",
      "Epoch 33 of 200:  16%|#6        | 32/200 [07:56<42:26, 15.16s/it, loss=5.33, accuracy=0.0054, f1_score=0.00527]\u001b[A\n",
      "Epoch 33 of 200:  16%|#6        | 32/200 [08:11<42:26, 15.16s/it, loss=5.33, accuracy=0.00533, f1_score=0.00536]\u001b[A\n",
      "Epoch 33 of 200:  16%|#6        | 33/200 [08:11<41:34, 14.94s/it, loss=5.33, accuracy=0.00533, f1_score=0.00536]\u001b[A\n",
      "Epoch 34 of 200:  16%|#6        | 33/200 [08:11<41:34, 14.94s/it, loss=5.33, accuracy=0.00533, f1_score=0.00536]\u001b[A\n",
      "Epoch 34 of 200:  16%|#6        | 33/200 [08:25<41:34, 14.94s/it, loss=5.33, accuracy=0.00526, f1_score=0.00529]\u001b[A\n",
      "Epoch 34 of 200:  17%|#7        | 34/200 [08:25<40:58, 14.81s/it, loss=5.33, accuracy=0.00526, f1_score=0.00529]\u001b[A\n",
      "Epoch 35 of 200:  17%|#7        | 34/200 [08:25<40:58, 14.81s/it, loss=5.33, accuracy=0.00526, f1_score=0.00529]\u001b[A\n",
      "Epoch 35 of 200:  17%|#7        | 34/200 [08:40<40:58, 14.81s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053] \u001b[A\n",
      "Epoch 35 of 200:  18%|#7        | 35/200 [08:40<40:24, 14.70s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 36 of 200:  18%|#7        | 35/200 [08:40<40:24, 14.70s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 36 of 200:  18%|#7        | 35/200 [08:54<40:24, 14.70s/it, loss=5.33, accuracy=0.00531, f1_score=0.00532]\u001b[A\n",
      "Epoch 36 of 200:  18%|#8        | 36/200 [08:54<40:00, 14.64s/it, loss=5.33, accuracy=0.00531, f1_score=0.00532]\u001b[A\n",
      "Epoch 37 of 200:  18%|#8        | 36/200 [08:54<40:00, 14.64s/it, loss=5.33, accuracy=0.00531, f1_score=0.00532]\u001b[A\n",
      "Epoch 37 of 200:  18%|#8        | 36/200 [09:09<40:00, 14.64s/it, loss=5.33, accuracy=0.0053, f1_score=0.00529] \u001b[A\n",
      "Epoch 37 of 200:  18%|#8        | 37/200 [09:09<39:33, 14.56s/it, loss=5.33, accuracy=0.0053, f1_score=0.00529]\u001b[A\n",
      "Epoch 38 of 200:  18%|#8        | 37/200 [09:09<39:33, 14.56s/it, loss=5.33, accuracy=0.0053, f1_score=0.00529]\u001b[A\n",
      "Epoch 38 of 200:  18%|#8        | 37/200 [09:23<39:33, 14.56s/it, loss=5.33, accuracy=0.00537, f1_score=0.00534]\u001b[A\n",
      "Epoch 38 of 200:  19%|#9        | 38/200 [09:23<39:16, 14.54s/it, loss=5.33, accuracy=0.00537, f1_score=0.00534]\u001b[A\n",
      "Epoch 39 of 200:  19%|#9        | 38/200 [09:23<39:16, 14.54s/it, loss=5.33, accuracy=0.00537, f1_score=0.00534]\u001b[A\n",
      "Epoch 39 of 200:  19%|#9        | 38/200 [09:38<39:16, 14.54s/it, loss=5.33, accuracy=0.00537, f1_score=0.00537]\u001b[A\n",
      "Epoch 39 of 200:  20%|#9        | 39/200 [09:38<39:00, 14.54s/it, loss=5.33, accuracy=0.00537, f1_score=0.00537]\u001b[A\n",
      "Epoch 40 of 200:  20%|#9        | 39/200 [09:38<39:00, 14.54s/it, loss=5.33, accuracy=0.00537, f1_score=0.00537]\u001b[A\n",
      "Epoch 40 of 200:  20%|#9        | 39/200 [09:52<39:00, 14.54s/it, loss=5.33, accuracy=0.00533, f1_score=0.00532]\u001b[A\n",
      "Epoch 40 of 200:  20%|##        | 40/200 [09:57<42:34, 15.97s/it, loss=5.33, accuracy=0.00533, f1_score=0.00532]\u001b[A\n",
      "Epoch 41 of 200:  20%|##        | 40/200 [09:57<42:34, 15.97s/it, loss=5.33, accuracy=0.00533, f1_score=0.00532]\u001b[A\n",
      "Epoch 41 of 200:  20%|##        | 40/200 [10:12<42:34, 15.97s/it, loss=5.33, accuracy=0.0053, f1_score=0.00533] \u001b[A\n",
      "Epoch 41 of 200:  20%|##        | 41/200 [10:12<41:10, 15.54s/it, loss=5.33, accuracy=0.0053, f1_score=0.00533]\u001b[A\n",
      "Epoch 42 of 200:  20%|##        | 41/200 [10:12<41:10, 15.54s/it, loss=5.33, accuracy=0.0053, f1_score=0.00533]\u001b[A\n",
      "Epoch 42 of 200:  20%|##        | 41/200 [10:26<41:10, 15.54s/it, loss=5.33, accuracy=0.00524, f1_score=0.00529]\u001b[A\n",
      "Epoch 42 of 200:  21%|##1       | 42/200 [10:26<40:06, 15.23s/it, loss=5.33, accuracy=0.00524, f1_score=0.00529]\u001b[A\n",
      "Epoch 43 of 200:  21%|##1       | 42/200 [10:26<40:06, 15.23s/it, loss=5.33, accuracy=0.00524, f1_score=0.00529]\u001b[A\n",
      "Epoch 43 of 200:  21%|##1       | 42/200 [10:41<40:06, 15.23s/it, loss=5.33, accuracy=0.0054, f1_score=0.00535] \u001b[A\n",
      "Epoch 43 of 200:  22%|##1       | 43/200 [10:41<39:13, 14.99s/it, loss=5.33, accuracy=0.0054, f1_score=0.00535]\u001b[A\n",
      "Epoch 44 of 200:  22%|##1       | 43/200 [10:41<39:13, 14.99s/it, loss=5.33, accuracy=0.0054, f1_score=0.00535]\u001b[A\n",
      "Epoch 44 of 200:  22%|##1       | 43/200 [10:55<39:13, 14.99s/it, loss=5.33, accuracy=0.00534, f1_score=0.0054]\u001b[A\n",
      "Epoch 44 of 200:  22%|##2       | 44/200 [10:55<38:36, 14.85s/it, loss=5.33, accuracy=0.00534, f1_score=0.0054]\u001b[A\n",
      "Epoch 45 of 200:  22%|##2       | 44/200 [10:55<38:36, 14.85s/it, loss=5.33, accuracy=0.00534, f1_score=0.0054]\u001b[A\n",
      "Epoch 45 of 200:  22%|##2       | 44/200 [11:09<38:36, 14.85s/it, loss=5.33, accuracy=0.00529, f1_score=0.00534]\u001b[A\n",
      "Epoch 45 of 200:  22%|##2       | 45/200 [11:09<37:59, 14.71s/it, loss=5.33, accuracy=0.00529, f1_score=0.00534]\u001b[A\n",
      "Epoch 46 of 200:  22%|##2       | 45/200 [11:09<37:59, 14.71s/it, loss=5.33, accuracy=0.00529, f1_score=0.00534]\u001b[A\n",
      "Epoch 46 of 200:  22%|##2       | 45/200 [11:24<37:59, 14.71s/it, loss=5.33, accuracy=0.00536, f1_score=0.0053] \u001b[A\n",
      "Epoch 46 of 200:  23%|##3       | 46/200 [11:24<37:35, 14.64s/it, loss=5.33, accuracy=0.00536, f1_score=0.0053]\u001b[A\n",
      "Epoch 47 of 200:  23%|##3       | 46/200 [11:24<37:35, 14.64s/it, loss=5.33, accuracy=0.00536, f1_score=0.0053]\u001b[A\n",
      "Epoch 47 of 200:  23%|##3       | 46/200 [11:38<37:35, 14.64s/it, loss=5.33, accuracy=0.00536, f1_score=0.00531]\u001b[A\n",
      "Epoch 47 of 200:  24%|##3       | 47/200 [11:38<37:09, 14.57s/it, loss=5.33, accuracy=0.00536, f1_score=0.00531]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 of 200:  24%|##3       | 47/200 [11:38<37:09, 14.57s/it, loss=5.33, accuracy=0.00536, f1_score=0.00531]\u001b[A\n",
      "Epoch 48 of 200:  24%|##3       | 47/200 [11:53<37:09, 14.57s/it, loss=5.33, accuracy=0.00525, f1_score=0.0053] \u001b[A\n",
      "Epoch 48 of 200:  24%|##4       | 48/200 [11:53<36:45, 14.51s/it, loss=5.33, accuracy=0.00525, f1_score=0.0053]\u001b[A\n",
      "Epoch 49 of 200:  24%|##4       | 48/200 [11:53<36:45, 14.51s/it, loss=5.33, accuracy=0.00525, f1_score=0.0053]\u001b[A\n",
      "Epoch 49 of 200:  24%|##4       | 48/200 [12:07<36:45, 14.51s/it, loss=5.33, accuracy=0.00531, f1_score=0.00533]\u001b[A\n",
      "Epoch 49 of 200:  24%|##4       | 49/200 [12:07<36:29, 14.50s/it, loss=5.33, accuracy=0.00531, f1_score=0.00533]\u001b[A\n",
      "Epoch 50 of 200:  24%|##4       | 49/200 [12:07<36:29, 14.50s/it, loss=5.33, accuracy=0.00531, f1_score=0.00533]\u001b[A\n",
      "Epoch 50 of 200:  24%|##4       | 49/200 [12:22<36:29, 14.50s/it, loss=5.33, accuracy=0.00534, f1_score=0.00535]\u001b[A\n",
      "Epoch 50 of 200:  25%|##5       | 50/200 [12:26<39:47, 15.91s/it, loss=5.33, accuracy=0.00534, f1_score=0.00535]\u001b[A\n",
      "Epoch 51 of 200:  25%|##5       | 50/200 [12:26<39:47, 15.91s/it, loss=5.33, accuracy=0.00534, f1_score=0.00535]\u001b[A\n",
      "Epoch 51 of 200:  25%|##5       | 50/200 [12:41<39:47, 15.91s/it, loss=5.33, accuracy=0.00531, f1_score=0.00538]\u001b[A\n",
      "Epoch 51 of 200:  26%|##5       | 51/200 [12:41<38:27, 15.49s/it, loss=5.33, accuracy=0.00531, f1_score=0.00538]\u001b[A\n",
      "Epoch 52 of 200:  26%|##5       | 51/200 [12:41<38:27, 15.49s/it, loss=5.33, accuracy=0.00531, f1_score=0.00538]\u001b[A\n",
      "Epoch 52 of 200:  26%|##5       | 51/200 [12:55<38:27, 15.49s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053] \u001b[A\n",
      "Epoch 52 of 200:  26%|##6       | 52/200 [12:55<37:26, 15.18s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 53 of 200:  26%|##6       | 52/200 [12:55<37:26, 15.18s/it, loss=5.33, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 53 of 200:  26%|##6       | 52/200 [13:10<37:26, 15.18s/it, loss=5.33, accuracy=0.00538, f1_score=0.00529]\u001b[A\n",
      "Epoch 53 of 200:  26%|##6       | 53/200 [13:10<36:39, 14.97s/it, loss=5.33, accuracy=0.00538, f1_score=0.00529]\u001b[A\n",
      "Epoch 54 of 200:  26%|##6       | 53/200 [13:10<36:39, 14.97s/it, loss=5.33, accuracy=0.00538, f1_score=0.00529]\u001b[A\n",
      "Epoch 54 of 200:  26%|##6       | 53/200 [13:24<36:39, 14.97s/it, loss=5.33, accuracy=0.00528, f1_score=0.00532]\u001b[A\n",
      "Epoch 54 of 200:  27%|##7       | 54/200 [13:24<36:00, 14.80s/it, loss=5.33, accuracy=0.00528, f1_score=0.00532]\u001b[A\n",
      "Epoch 55 of 200:  27%|##7       | 54/200 [13:24<36:00, 14.80s/it, loss=5.33, accuracy=0.00528, f1_score=0.00532]\u001b[A\n",
      "Epoch 55 of 200:  27%|##7       | 54/200 [13:39<36:00, 14.80s/it, loss=5.32, accuracy=0.00526, f1_score=0.00537]\u001b[A\n",
      "Epoch 55 of 200:  28%|##7       | 55/200 [13:39<35:28, 14.68s/it, loss=5.32, accuracy=0.00526, f1_score=0.00537]\u001b[A\n",
      "Epoch 56 of 200:  28%|##7       | 55/200 [13:39<35:28, 14.68s/it, loss=5.32, accuracy=0.00526, f1_score=0.00537]\u001b[A\n",
      "Epoch 56 of 200:  28%|##7       | 55/200 [13:53<35:28, 14.68s/it, loss=5.32, accuracy=0.00535, f1_score=0.00534]\u001b[A\n",
      "Epoch 56 of 200:  28%|##8       | 56/200 [13:53<35:01, 14.59s/it, loss=5.32, accuracy=0.00535, f1_score=0.00534]\u001b[A\n",
      "Epoch 57 of 200:  28%|##8       | 56/200 [13:53<35:01, 14.59s/it, loss=5.32, accuracy=0.00535, f1_score=0.00534]\u001b[A\n",
      "Epoch 57 of 200:  28%|##8       | 56/200 [14:08<35:01, 14.59s/it, loss=5.32, accuracy=0.00549, f1_score=0.0054] \u001b[A\n",
      "Epoch 57 of 200:  28%|##8       | 57/200 [14:08<34:44, 14.58s/it, loss=5.32, accuracy=0.00549, f1_score=0.0054]\u001b[A\n",
      "Epoch 58 of 200:  28%|##8       | 57/200 [14:08<34:44, 14.58s/it, loss=5.32, accuracy=0.00549, f1_score=0.0054]\u001b[A\n",
      "Epoch 58 of 200:  28%|##8       | 57/200 [14:22<34:44, 14.58s/it, loss=5.32, accuracy=0.00531, f1_score=0.00527]\u001b[A\n",
      "Epoch 58 of 200:  29%|##9       | 58/200 [14:22<34:23, 14.53s/it, loss=5.32, accuracy=0.00531, f1_score=0.00527]\u001b[A\n",
      "Epoch 59 of 200:  29%|##9       | 58/200 [14:22<34:23, 14.53s/it, loss=5.32, accuracy=0.00531, f1_score=0.00527]\u001b[A\n",
      "Epoch 59 of 200:  29%|##9       | 58/200 [14:36<34:23, 14.53s/it, loss=5.32, accuracy=0.00535, f1_score=0.00535]\u001b[A\n",
      "Epoch 59 of 200:  30%|##9       | 59/200 [14:36<34:07, 14.52s/it, loss=5.32, accuracy=0.00535, f1_score=0.00535]\u001b[A\n",
      "Epoch 60 of 200:  30%|##9       | 59/200 [14:36<34:07, 14.52s/it, loss=5.32, accuracy=0.00535, f1_score=0.00535]\u001b[A\n",
      "Epoch 60 of 200:  30%|##9       | 59/200 [14:51<34:07, 14.52s/it, loss=5.32, accuracy=0.00533, f1_score=0.00528]\u001b[A\n",
      "Epoch 60 of 200:  30%|###       | 60/200 [14:56<37:13, 15.95s/it, loss=5.32, accuracy=0.00533, f1_score=0.00528]\u001b[A\n",
      "Epoch 61 of 200:  30%|###       | 60/200 [14:56<37:13, 15.95s/it, loss=5.32, accuracy=0.00533, f1_score=0.00528]\u001b[A\n",
      "Epoch 61 of 200:  30%|###       | 60/200 [15:10<37:13, 15.95s/it, loss=5.32, accuracy=0.00531, f1_score=0.00533]\u001b[A\n",
      "Epoch 61 of 200:  30%|###       | 61/200 [15:10<35:58, 15.53s/it, loss=5.32, accuracy=0.00531, f1_score=0.00533]\u001b[A\n",
      "Epoch 62 of 200:  30%|###       | 61/200 [15:10<35:58, 15.53s/it, loss=5.32, accuracy=0.00531, f1_score=0.00533]\u001b[A\n",
      "Epoch 62 of 200:  30%|###       | 61/200 [15:25<35:58, 15.53s/it, loss=5.32, accuracy=0.00536, f1_score=0.00537]\u001b[A\n",
      "Epoch 62 of 200:  31%|###1      | 62/200 [15:25<34:56, 15.20s/it, loss=5.32, accuracy=0.00536, f1_score=0.00537]\u001b[A\n",
      "Epoch 63 of 200:  31%|###1      | 62/200 [15:25<34:56, 15.20s/it, loss=5.32, accuracy=0.00536, f1_score=0.00537]\u001b[A\n",
      "Epoch 63 of 200:  31%|###1      | 62/200 [15:39<34:56, 15.20s/it, loss=5.32, accuracy=0.00542, f1_score=0.00539]\u001b[A\n",
      "Epoch 63 of 200:  32%|###1      | 63/200 [15:39<34:09, 14.96s/it, loss=5.32, accuracy=0.00542, f1_score=0.00539]\u001b[A\n",
      "Epoch 64 of 200:  32%|###1      | 63/200 [15:39<34:09, 14.96s/it, loss=5.32, accuracy=0.00542, f1_score=0.00539]\u001b[A\n",
      "Epoch 64 of 200:  32%|###1      | 63/200 [15:54<34:09, 14.96s/it, loss=5.32, accuracy=0.00532, f1_score=0.0053] \u001b[A\n",
      "Epoch 64 of 200:  32%|###2      | 64/200 [15:54<33:32, 14.80s/it, loss=5.32, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 65 of 200:  32%|###2      | 64/200 [15:54<33:32, 14.80s/it, loss=5.32, accuracy=0.00532, f1_score=0.0053]\u001b[A\n",
      "Epoch 65 of 200:  32%|###2      | 64/200 [16:08<33:32, 14.80s/it, loss=5.32, accuracy=0.00529, f1_score=0.0053]\u001b[A\n",
      "Epoch 65 of 200:  32%|###2      | 65/200 [16:08<33:06, 14.72s/it, loss=5.32, accuracy=0.00529, f1_score=0.0053]\u001b[A\n",
      "Epoch 66 of 200:  32%|###2      | 65/200 [16:08<33:06, 14.72s/it, loss=5.32, accuracy=0.00529, f1_score=0.0053]\u001b[A\n",
      "Epoch 66 of 200:  32%|###2      | 65/200 [16:23<33:06, 14.72s/it, loss=5.32, accuracy=0.0053, f1_score=0.00533]\u001b[A\n",
      "Epoch 66 of 200:  33%|###3      | 66/200 [16:23<32:41, 14.64s/it, loss=5.32, accuracy=0.0053, f1_score=0.00533]\u001b[A\n",
      "Epoch 67 of 200:  33%|###3      | 66/200 [16:23<32:41, 14.64s/it, loss=5.32, accuracy=0.0053, f1_score=0.00533]\u001b[A\n",
      "Epoch 67 of 200:  33%|###3      | 66/200 [16:37<32:41, 14.64s/it, loss=5.32, accuracy=0.00525, f1_score=0.00534]\u001b[A\n",
      "Epoch 67 of 200:  34%|###3      | 67/200 [16:37<32:18, 14.57s/it, loss=5.32, accuracy=0.00525, f1_score=0.00534]\u001b[A\n",
      "Epoch 68 of 200:  34%|###3      | 67/200 [16:37<32:18, 14.57s/it, loss=5.32, accuracy=0.00525, f1_score=0.00534]\u001b[A\n",
      "Epoch 68 of 200:  34%|###3      | 67/200 [16:51<32:18, 14.57s/it, loss=5.32, accuracy=0.00533, f1_score=0.00533]\u001b[A\n",
      "Epoch 68 of 200:  34%|###4      | 68/200 [16:51<32:01, 14.55s/it, loss=5.32, accuracy=0.00533, f1_score=0.00533]\u001b[A\n",
      "Epoch 69 of 200:  34%|###4      | 68/200 [16:51<32:01, 14.55s/it, loss=5.32, accuracy=0.00533, f1_score=0.00533]\u001b[A\n",
      "Epoch 69 of 200:  34%|###4      | 68/200 [17:06<32:01, 14.55s/it, loss=5.32, accuracy=0.00532, f1_score=0.00535]\u001b[A\n",
      "Epoch 69 of 200:  34%|###4      | 69/200 [17:06<31:42, 14.52s/it, loss=5.32, accuracy=0.00532, f1_score=0.00535]\u001b[A\n",
      "Epoch 70 of 200:  34%|###4      | 69/200 [17:06<31:42, 14.52s/it, loss=5.32, accuracy=0.00532, f1_score=0.00535]\u001b[A\n",
      "Epoch 70 of 200:  34%|###4      | 69/200 [17:20<31:42, 14.52s/it, loss=5.32, accuracy=0.00529, f1_score=0.0053] \u001b[A\n",
      "Epoch 70 of 200:  35%|###5      | 70/200 [17:25<34:38, 15.99s/it, loss=5.32, accuracy=0.00529, f1_score=0.0053]\u001b[A\n",
      "Epoch 71 of 200:  35%|###5      | 70/200 [17:25<34:38, 15.99s/it, loss=5.32, accuracy=0.00529, f1_score=0.0053]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 of 200:  35%|###5      | 70/200 [17:40<34:38, 15.99s/it, loss=5.32, accuracy=0.0052, f1_score=0.00528]\u001b[A\n",
      "Epoch 71 of 200:  36%|###5      | 71/200 [17:40<33:21, 15.52s/it, loss=5.32, accuracy=0.0052, f1_score=0.00528]\u001b[A\n",
      "Epoch 72 of 200:  36%|###5      | 71/200 [17:40<33:21, 15.52s/it, loss=5.32, accuracy=0.0052, f1_score=0.00528]\u001b[A"
     ]
    }
   ],
   "source": [
    "# here we apply a bayesian optimization for finding the best hyperparameters\n",
    "best_hparams = fmin(objective, EXPERIMENT_SPACE, algo=tpe.suggest)\n",
    "print(best_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "D-IK CompVision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
